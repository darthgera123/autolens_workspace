{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task 2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uREt5YQY_ZYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNsfX3RMQj65",
        "colab_type": "text"
      },
      "source": [
        "# Approach\n",
        "We want to point out the anomalies. The idea is to use a convolutional autoencoder as mentioned above. We try to learn the dark matter representation using an autoencoder. The latent space is the representation of the dark matter. After that we try to reconstruct it back. The ones with the highest Mean Absolute Error will be the ones which can be considered an anomaly. We run this on both the datasets and try to figure out the anomalies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf6vPKfyaK3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lenses(Dataset):\n",
        "\n",
        "  def __init__(self,img_dir,split,transforms=None,train=True):\n",
        "    super(Lenses, self).__init__()\n",
        "    self.img_dir = img_dir\n",
        "    self.transforms = transforms\n",
        "    if train:\n",
        "      self.imgs =  sorted(os.listdir(self.img_dir))[:split]\n",
        "    else:\n",
        "      self.imgs = sorted(os.listdir(self.img_dir))[split:]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.imgs)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    img = cv2.imread(self.img_dir+self.imgs[index])\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (128,128), interpolation = cv2.INTER_AREA)\n",
        "    if self.transforms != None:\n",
        "      img = self.transforms(img)\n",
        "    return img\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gKvfen2FUPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transforms= transforms.Compose([transforms.ToPILImage(),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                                      \n",
        "                                      ])\n",
        "# train_transforms = None\n",
        "train_data = Lenses(\"drive/My Drive/lenses/sub/\",4000,train_transforms,True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHu3h06uFYaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(m):\n",
        "\tif  type(m) != nn.Sequential and type(m) != nn.Upsample and type(m) != nn.ReLU and type(m) != nn.Sigmoid \t\tand type(m) != nn.LeakyReLU and type(m) != nn.MaxPool2d and type(m) != nn.Tanh and type(m) != nn.BatchNorm2d:\n",
        "\t\tnn.init.xavier_uniform_(m.weight)\n",
        "\t\tm.bias.data.fill_(0.01)\n",
        "\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AutoEncoder,self).__init__()\n",
        "#         input = 256*256*10\n",
        "        self.encoder = nn.Sequential(nn.Conv2d(3,16,kernel_size=3,padding=1),\n",
        "                                     nn.ReLU(),\n",
        "                                     nn.MaxPool2d(2),\n",
        "                                     nn.Conv2d(16,32,kernel_size=3,padding=1),\n",
        "                                     nn.ReLU(),\n",
        "                                     nn.MaxPool2d(2),\n",
        "                                     nn.Conv2d(32,64,kernel_size=3,padding=1),\n",
        "                                     nn.ReLU(),\n",
        "                                     nn.MaxPool2d(2))\n",
        "        self.decoder = nn.Sequential(nn.ConvTranspose2d(64,32,kernel_size=3,padding=1),\n",
        "                                     nn.ReLU(),\n",
        "                                     nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "                                     nn.ConvTranspose2d(32,16,kernel_size=3,padding=1),\n",
        "                                     nn.ReLU(),\n",
        "                                     nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "\n",
        "                                     nn.ConvTranspose2d(16,3,kernel_size=3,padding=1),\n",
        "                                     nn.ReLU(),\n",
        "                                     nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "                                     )\n",
        "    \n",
        "    def initialise_weights(self):\n",
        "        self.decoder.apply(init_weights)\n",
        "        self.encoder.apply(init_weights)\n",
        "\n",
        "    def forward(self,img):\n",
        "        # print(\"Image Shape: \",img.shape)\n",
        "        encoded = self.encoder(img)\n",
        "        # print(\"Rep Shape: \", encoded.shape)\n",
        "        decoded = self.decoder(encoded)\n",
        "        # print(\"Recon shape: \",decoded.shape)\n",
        "        \n",
        "        return decoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li0tx5uDaJPx",
        "colab_type": "text"
      },
      "source": [
        "# Autoencoder\n",
        "Our Auto encoder consists of an encoder and decoder. The encoder consists of 3 Conv+Maxpool layers. We compress it to 16x16x64 volume. The decoder then tries to reconstruct it back."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3QPrSsFOOrt",
        "colab_type": "code",
        "outputId": "d77ad97a-a111-46d9-b0fc-85988e6e9f25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "model = AutoEncoder()\n",
        "model.initialise_weights()\n",
        "if train_on_gpu:\n",
        "    print(\"Yes Gpu is on\")\n",
        "    model = model.cuda()\n",
        "else:\n",
        "    print(\"Time to sleep\")\n",
        "error = nn.L1Loss()\n",
        "opt = optim.Adam(model.parameters(), lr = 0.001,weight_decay=5e-4)\n",
        "batch = 8\n",
        "valid_size = 0.2\n",
        "num = train_data.__len__()\n",
        "indices = list(range(num))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size*num))\n",
        "train_idx,valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size = batch, sampler = train_sampler)\n",
        "valid_loader = DataLoader(train_data, batch_size = batch, sampler = valid_sampler)\n",
        "\n",
        "if train_on_gpu:\n",
        "    model.cuda()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yes Gpu is on\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN7FYT3ET-b1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_losses =[]\n",
        "valid_losses =[]\n",
        "n_epochs = 20\n",
        "valid_loss_min = np.Inf\n",
        "for epoch in range(n_epochs):\n",
        "  train_loss = 0.0\n",
        "  valid_loss = 0.0\n",
        "  model.train()\n",
        "  for data in train_loader:\n",
        "      if train_on_gpu:\n",
        "          data = data.cuda()\n",
        "      opt.zero_grad()\n",
        "      output = model(data)\n",
        "      loss = error(output,data)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      train_loss += loss.item()*data.size(0)\n",
        "  model.eval()\n",
        "  for data in valid_loader:\n",
        "      if train_on_gpu:\n",
        "        data = data.cuda()\n",
        "      output = model(data)\n",
        "      loss = error(output,data)\n",
        "      valid_loss += loss.item()*data.size(0)\n",
        "  train_losses.append(train_loss)\n",
        "  valid_losses.append(valid_loss)\n",
        "  print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch, train_loss, valid_loss))\n",
        "\n",
        "  if valid_loss <= valid_loss_min:\n",
        "    print(\"Validation Loss decreased {:0.6f} -> {:0.6f}\".format(valid_loss_min,valid_loss))\n",
        "    valid_loss_min = valid_loss\n",
        "    torch.save(model.state_dict(), 'drive/My Drive/best_model_so_far_lenses.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozj2hmuJdwyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_transforms= transforms.Compose([transforms.ToPILImage(),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225)),\n",
        "                                      \n",
        "                                      ])\n",
        "test_data = Lenses(\"drive/My Drive/small_lenses/sub/\",1500,train_transforms,False)\n",
        "\n",
        "test_loader = DataLoader(test_data, batch_size=1, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gtzdVTOmTxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(torch.load('drive/My Drive/best_model_so_far_lenses.pt'))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "preds = []\n",
        "for batch_i, data in enumerate(test_loader):\n",
        "    data = data.cuda()\n",
        "    output = model(data)\n",
        "    s = dict()\n",
        "    s['error'] = error(output,data).item()\n",
        "    s['img'] = torch.Tensor.cpu(data).detach().numpy()\n",
        "    preds.append(s) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGEe3ccJnCST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}